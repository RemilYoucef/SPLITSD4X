{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" Import the libraries \" \n",
    "\n",
    "import os\n",
    "import sys \n",
    "import math\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" Import the scripts of SD for Explaining \"\n",
    "\n",
    "absFilePath = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "newPath = os.path.join(absFilePath, 'SplitSD4X\\\\')\n",
    "sys.path.append(newPath)\n",
    "\n",
    "newPath_supp = os.path.join(newPath, 'supplementary')\n",
    "sys.path.append(newPath_supp)\n",
    "\n",
    "from performances import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" Import matplotlib and sns to display graphs and figures \"\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import transforms\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" Import the plot functions\"\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from plotFunctions.PlotMSENeighborGen import *\n",
    "from plotFunctions.PlotMSENbNeighbors import *\n",
    "from plotFunctions.PlotMSEDiscr import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" Define the functions to save and load data \"\n",
    "import pickle\n",
    "def save_obj(obj, name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Test the effectiveness of the neighbors generation approaches  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" LOAD THE DATA \"\n",
    "\n",
    "path = './saved_data/'\n",
    "\n",
    "data_train   = load_obj(path + 'data_train')\n",
    "target_train = load_obj(path + 'target_train')\n",
    "data_test    = load_obj(path  + 'data_test')\n",
    "target_test  = load_obj(path + 'target_test')\n",
    "\n",
    "all_lists_neigh = []\n",
    "all_lists_neigh.append(load_obj(path   + 'list_neighbors_1'))\n",
    "all_lists_neigh.append(load_obj(path   + 'list_neighbors_2'))\n",
    "all_lists_neigh.append(load_obj(path   + 'list_neighbors_3'))\n",
    "all_lists_neigh.append(load_obj(path   + 'list_neighbors_4'))\n",
    "\n",
    "all_lists_subgroups = []\n",
    "all_lists_subgroups.append(load_obj(path + 'list_subgroups_1'))\n",
    "all_lists_subgroups.append(load_obj(path + 'list_subgroups_2'))\n",
    "all_lists_subgroups.append(load_obj(path + 'list_subgroups_3'))\n",
    "all_lists_subgroups.append(load_obj(path + 'list_subgroups_4'))\n",
    "\n",
    "\" Number of instances to explain \"\n",
    "n = np.size(data_test,0) \n",
    "\n",
    "\" Number of neighbors \"\n",
    "nb_neighs = np.size(all_lists_neigh[0][0],0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" using Sklearn MLP regressor as black box: \"\n",
    "\n",
    "mlp = make_pipeline(StandardScaler(),\n",
    "                    MLPRegressor(hidden_layer_sizes=(50, 50),\n",
    "                                 tol=1e-2, \n",
    "                                 max_iter=1000, \n",
    "                                 random_state=0))\n",
    "model_nt = mlp.fit(data_train, target_train)\n",
    "target_pred_nt = model_nt.predict(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  MSE Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data_to_plot/'\n",
    "f_mse = open(path + \"mse_generation.txt\",\"w\")\n",
    "f_mse.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_models_max = 100\n",
    "f_mse = open(path + \"mse_generation.txt\",\"a\")\n",
    "\n",
    "for j in range (0,4) :\n",
    "    f_mse.write(\"Generation_\"+str(j+1)+\"\\n\")\n",
    "    list_subgroups = all_lists_subgroups[j]\n",
    "    list_neigh = all_lists_neigh[j]\n",
    "    for i in range (0,nb_models_max-1) :\n",
    "        S = list_subgroups[i]\n",
    "        sse_S = loss_sd (S,data_test,list_neigh,model_nt)\n",
    "        mse_S = sse_S / (n * nb_neighs)\n",
    "        f_mse.write('{:.2e}'.format(mse_S)+'\\n')\n",
    "f_mse.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  *MSE Error Graph*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotMSEwrtNbModels('parkinsons',path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test the influence of the number of neighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" LOAD THE DATA \"\n",
    "\n",
    "path = './saved_data/'\n",
    "\n",
    "data_train   = load_obj(path + 'data_train_n')\n",
    "target_train = load_obj(path + 'target_train_n')\n",
    "data_test    = load_obj(path  + 'data_test_n')\n",
    "target_test  = load_obj(path + 'target_test_n')\n",
    "\n",
    "all_lists_neigh = []\n",
    "all_lists_neigh.append(load_obj(path   + 'list_neighbors_20'))\n",
    "all_lists_neigh.append(load_obj(path   + 'list_neighbors_50'))\n",
    "all_lists_neigh.append(load_obj(path   + 'list_neighbors_100'))\n",
    "\n",
    "all_lists_subgroups = []\n",
    "all_lists_subgroups.append(load_obj(path + 'list_subgroups_20'))\n",
    "all_lists_subgroups.append(load_obj(path + 'list_subgroups_50'))\n",
    "all_lists_subgroups.append(load_obj(path + 'list_subgroups_100'))\n",
    "\n",
    "\" Number of instances to explain \"\n",
    "n = np.size(data_test,0) \n",
    "\n",
    "\" Number of neighbors \"\n",
    "nb_neighs = [20,50,100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" using Sklearn MLP regressor as black box: \"\n",
    "\n",
    "mlp = make_pipeline(StandardScaler(),\n",
    "                    MLPRegressor(hidden_layer_sizes=(50, 50),\n",
    "                                 tol=1e-2, \n",
    "                                 max_iter=1000, \n",
    "                                 random_state=0))\n",
    "model_nt = mlp.fit(data_train, target_train)\n",
    "target_pred_nt = model_nt.predict(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  MSE Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data_to_plot/'\n",
    "f_mse = open(path + \"mse_nb_neighs.txt\",\"w\")\n",
    "f_mse.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_models_max = 100\n",
    "f_mse = open(path + \"mse_nb_neighs.txt\",\"a\")\n",
    "\n",
    "for j in range (0,3) :\n",
    "    f_mse.write(\"Generation_\"+str(j+1)+\"\\n\")\n",
    "    list_subgroups = all_lists_subgroups[j]\n",
    "    list_neigh = all_lists_neigh[j]\n",
    "    for i in range (0,nb_models_max-1) :\n",
    "        S = list_subgroups[i]\n",
    "        sse_S = loss_sd (S,data_test,list_neigh,model_nt)\n",
    "        mse_S = sse_S / (n * nb_neighs[j])\n",
    "        f_mse.write('{:.2e}'.format(mse_S)+'\\n')\n",
    "f_mse.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotMSENbNeighbors('parkinsons',path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test the parameter K of discretization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" LOAD THE DATA \"\n",
    "\n",
    "path = './saved_data/'\n",
    "\n",
    "data_train   = load_obj(path + 'data_train_d')\n",
    "target_train = load_obj(path + 'target_train_d')\n",
    "data_test    = load_obj(path  + 'data_test_d')\n",
    "target_test  = load_obj(path + 'target_test_d')\n",
    "list_neigh = load_obj(path   + 'list_neighbors_d')\n",
    "\n",
    "L_Subgroups_freq = load_obj(path + 'l_list_subgroups_freq')\n",
    "L_Subgroups_width = load_obj(path + 'l_list_subgroups_width')\n",
    "\n",
    "\" Number of instances to explain \"\n",
    "n = np.size(data_test,0) \n",
    "\n",
    "\" Number of neighbors \"\n",
    "nb_neighs = np.size(list_neigh[0],0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" using Sklearn MLP regressor as black box: \"\n",
    "\n",
    "mlp = make_pipeline(StandardScaler(),\n",
    "                    MLPRegressor(hidden_layer_sizes=(50, 50),\n",
    "                                 tol=1e-2, \n",
    "                                 max_iter=1000, \n",
    "                                 random_state=0))\n",
    "model_nt = mlp.fit(data_train, target_train)\n",
    "target_pred_nt = model_nt.predict(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1  Equal Frequency  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  MSE Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data_to_plot/'\n",
    "f_mse = open(path + \"mse_disc_freq.txt\",\"w\")\n",
    "f_mse.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_models_max = 100\n",
    "f_mse = open(path + \"mse_disc_freq.txt\",\"a\")\n",
    "\n",
    "for j in range (0,len(L_Subgroups_freq)) :\n",
    "    f_mse.write(\"Generation_\"+str(j+1)+\"\\n\")\n",
    "    list_subgroups = L_Subgroups_freq[j]\n",
    "    for i in range (0,nb_models_max-1) :\n",
    "        S = list_subgroups[i]\n",
    "        sse_S = loss_sd (S,data_test,list_neigh,model_nt)\n",
    "        mse_S = sse_S / (n * nb_neighs)\n",
    "        f_mse.write('{:.2e}'.format(mse_S)+'\\n')\n",
    "f_mse.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotMSEDiscFreq('parkinsons',path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1  Equal Width  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data_to_plot/'\n",
    "f_mse = open(path + \"mse_disc_width.txt\",\"w\")\n",
    "f_mse.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_models_max = 100\n",
    "f_mse = open(path + \"mse_disc_width.txt\",\"a\")\n",
    "\n",
    "for j in range (0,len(L_Subgroups_width)) :\n",
    "    f_mse.write(\"Generation_\"+str(j+1)+\"\\n\")\n",
    "    list_subgroups = L_Subgroups_width[j]\n",
    "    for i in range (0,nb_models_max-1) :\n",
    "        S = list_subgroups[i]\n",
    "        sse_S = loss_sd (S,data_test,list_neigh,model_nt)\n",
    "        mse_S = sse_S / (n * nb_neighs)\n",
    "        f_mse.write('{:.2e}'.format(mse_S)+'\\n')\n",
    "f_mse.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotMSEDiscWidth('parkinsons',path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
